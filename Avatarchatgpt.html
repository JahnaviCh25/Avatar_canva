<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Interactive Avatar Assistant</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f0f0f0;
        }
        .container {
            margin-top: 50px;
        }
        .avatar-container {
            width: 300px;
            height: 300px;
            margin: 0 auto;
            border-radius: 50%;
            overflow: hidden;
            border: 4px solid #444;
            transition: transform 0.2s ease-in-out;
        }
        .avatar-container img {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        .description {
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Meet JC's Virtual Assistant!</h1>
        <div class="avatar-container" id="avatar">
            <img src="https://raw.githubusercontent.com/JahnaviCh25/Avatar_canva/main/Image.png" alt="Avatar"> <!-- GitHub-hosted avatar image -->
        </div>
        <div class="description">
            <p>This is our virtual assistant! Ask it anything.</p>
            <button id="start-record-btn">Start Talking</button>
            <p id="result"></p>
            <p id="response"></p> <!-- Paragraph to display the ChatGPT response -->
        </div>
    </div>

    <script>
        const startRecordBtn = document.getElementById('start-record-btn');
        const resultParagraph = document.getElementById('result');
        const responseParagraph = document.getElementById('response'); // Display ChatGPT response
        const avatar = document.getElementById('avatar'); // Avatar container

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();

        const apiKey = "sk-proj-lSsBEM5NAMqvKNHdViH0T3BlbkFJleGR206NvIe9w0KoqrbQ"; // Your OpenAI API Key
        const orgId = "org-ACJqOd4iJkK1zKscWrSnsQcF"; // Your OpenAI Organization ID

        startRecordBtn.addEventListener('click', function () {
            recognition.start();
        });

        recognition.onstart = function () {
            resultParagraph.textContent = "Voice recognition activated. Speak now.";
        };

        recognition.onresult = async function (event) {
            const transcript = event.results[0][0].transcript.toLowerCase();
            resultParagraph.textContent = "You said: " + transcript;

            let response;

            if (transcript.includes("time")) {
                const currentTime = new Date().toLocaleTimeString();
                response = `The current time is ${currentTime}.`;
            } else {
                try {
                    response = await getChatGPTResponse(transcript);
                } catch (error) {
                    console.error("Error processing response:", error);
                    response = "Sorry, something went wrong.";
                }
            }

            responseParagraph.textContent = "Assistant: " + response;

            try {
                const audioUrl = await textToSpeech(response);
                if (audioUrl) {
                    playAudio(audioUrl); // Play the response audio with avatar animation
                } else {
                    console.error("No audio URL returned.");
                }
            } catch (error) {
                console.error("Error generating speech:", error);
            }
        };

        recognition.onerror = function (event) {
            resultParagraph.textContent = "Error occurred in recognition: " + event.error;
        };

        async function getChatGPTResponse(userInput) {
            console.log("User Input:", userInput); // Log the user input
            try {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`,
                        'OpenAI-Organization': orgId
                    },
                    body: JSON.stringify({
                        model: 'gpt-3.5-turbo',
                        messages: [{ role: 'user', content: userInput }]
                    })
                });

                console.log("API Response Status:", response.status); // Log the response status

                if (!response.ok) {
                    throw new Error(`Error ${response.status}: ${response.statusText}`);
                }

                const data = await response.json();
                console.log("API Response Data:", data); // Log the data received from API
                return data.choices[0].message.content;
            } catch (error) {
                console.error("Error fetching ChatGPT response:", error);
                return "I couldn't understand. Please try again.";
            }
        }

        async function textToSpeech(text) {
            try {
                // Replace this with your actual Text-to-Speech API endpoint
                const response = await fetch('https://api.text-to-speech.example.com/generate', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: text })
                });

                if (!response.ok) {
                    throw new Error(`Error ${response.status}: ${response.statusText}`);
                }

                const data = await response.json();
                return data.audio_url; // Ensure this is the correct field from your TTS API response
            } catch (error) {
                console.error("Error generating speech:", error);
                return null;
            }
        }

        function playAudio(audioUrl) {
            const audio = new Audio(audioUrl);

            // Simulate avatar "speaking" by scaling the avatar
            avatar.style.transform = "scale(1.1)"; // Enlarge when speaking

            audio.play();

            audio.onended = () => {
                avatar.style.transform = "scale(1)"; // Reset size when done
                recognition.start(); // Restart voice recognition for the user to speak again
            };
        }
    </script>
</body>
</html>
